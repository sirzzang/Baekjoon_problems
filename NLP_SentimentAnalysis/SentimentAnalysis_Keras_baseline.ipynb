{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_Keras_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8tLKC0L0pQMM"
      ],
      "toc_visible": true,
      "mount_file_id": "1wXLbPZT0ZON9JD_QQDXTA8ltr-1JUmyK",
      "authorship_tag": "ABX9TyPwGMXAVx6IjkeLYqTPqs9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sirzzang/Baekjoon_problems/blob/master/NLP_SentimentAnalysis/SentimentAnalysis_Keras_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cGYORzQ0faj",
        "colab_type": "text"
      },
      "source": [
        " 긍정, 중립, 부정의 3클래스로 정책에 대한 인터넷 댓글 및 게시물 데이터를 분류하기 위해 Baseline 코드를 작성했습니다. 단어 단위로 토크나이징을 진행했고, 사전학습된 임베딩 모델도 사용하지 않은, 말 그대로 **기초적**인, 비교 목적의 코드입니다. 부족한 부분이 많습니다. 클래스화되지 않아 커스텀의 여지가 적고, 모델 구성도 간단합니다.\n",
        " \n",
        " 그럼에도 불구하고 읽어 주셔서 감사합니다. 앞으로 더 발전시켜 나가겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gta_YRHAwY9V",
        "colab_type": "text"
      },
      "source": [
        "# [0] Module Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlSWlQ5ZXYz3",
        "colab_type": "code",
        "outputId": "bf5017b4-c90e-4f9c-b0d6-011d865e7c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# KoNLPy 설치\n",
        "! pip3 install konlpy\n",
        "! wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
        "! tar xvfz mecab-0.996-ko-0.9.2.tar.gz > /dev/null 2>&1\n",
        "! ./configure > /dev/null 2>&1\n",
        "! make > /dev/null 2>&1\n",
        "! make check > /dev/null 2>&1\n",
        "! make install > /dev/null 2>&1\n",
        "! ldconfig > /dev/null 2>&1\n",
        "! wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
        "! tar xvfz mecab-ko-dic-2.1.1-20180720.tar.gz > /dev/null 2>&1\n",
        "! ./configure > /dev/null 2>&1\n",
        "! make > /dev/null 2>&1\n",
        "! make install > /dev/null 2>&1\n",
        "! apt-get update > /dev/null 2>&1\n",
        "! apt-get upgrade > /dev/null 2>&1\n",
        "! apt install curl > /dev/null 2>&1\n",
        "! apt install git > /dev/null 2>&1\n",
        "! bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)  > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.7MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.3)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/c9/cde4aae2f4ae7da6b46258d7233511f8b8f1468a3c782c0f2d70e61038b1/JPype1-0.7.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Installing collected packages: colorama, beautifulsoup4, JPype1, tweepy, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.3 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n",
            "--2020-04-25 17:31:32--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=IyZu1Y17xvzmIwcG1743RQCER10%3D&Expires=1587837319&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n",
            "--2020-04-25 17:31:32--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=IyZu1Y17xvzmIwcG1743RQCER10%3D&Expires=1587837319&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.233.147\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.233.147|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.43MB/s    in 0.2s    \n",
            "\n",
            "2020-04-25 17:31:33 (7.43 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "--2020-04-25 17:31:45--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=AoKBHHO2AU56EClWc5BT%2Bm%2BO7Dg%3D&Expires=1587837705&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n",
            "--2020-04-25 17:31:45--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=AoKBHHO2AU56EClWc5BT%2Bm%2BO7Dg%3D&Expires=1587837705&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.46.156\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.46.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  64.4MB/s    in 0.7s    \n",
            "\n",
            "2020-04-25 17:31:46 (64.4 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl7J4WsmwjUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import \n",
        "from __future__ import division \n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Masking, Bidirectional, Dense, Embedding, SimpleRNN, LSTM, GRU, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import datetime\n",
        "from fnmatch import fnmatch\n",
        "from pytz import timezone, utc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAfyQJjds2Fk",
        "colab_type": "text"
      },
      "source": [
        "# [1] 데이터 준비\n",
        "\n",
        "### 학습용 : `train.pickle`\n",
        "![학습 데이터](https://drive.google.com/uc?id=1FXmnCgv49GFJqFiBmI50G6sqYiuxwxka)\n",
        "\n",
        "### 예측용 : `predict.pickle`\n",
        "![예측 데이터](https://drive.google.com/uc?id=1NV-Yry3R8ezUb1lnJfhTCSjX8OAzLs42)\n",
        "\n",
        "\n",
        "* 학습, 예측을 위한 데이터를 준비하는 함수입니다.\n",
        "* 학습용으로 쓰일 데이터는 위와 같은 형태입니다. 실제로는 데이터를 불러온 뒤 진행해야 할 작업(결측값 처리, 중복값 제거 등)이 훨씬 더 많습니다.\n",
        "    - 이전 과정에서부터 진행해 오며 필요한 최소한의 전처리는 완료된 상태입니다.\n",
        "    - 원래 형태소 분석기를 사용해야 하지만, 시간 및 개발환경 상의 문제로 미리 형태소 분석을 해 놓았습니다.\n",
        "* 로드 과정에서의 문제로 `.csv`가 아니라 `.pickle` 형태로 저장했습니다.\n",
        "* 1은 긍정, 0은 중립/판단불가, -1은 부정을 나타냅니다. 팀원들과 직접 감성어 사전을 구축하고 라벨링한 결과입니다. 원핫 인코딩을 진행하면 긍정이 [0, 1, 0], 중립이 [1, 0, 0], 부정이 [0, 0, 1]로 변환됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbU-6NUGgs3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(path, is_predict):    \n",
        "    if is_predict:\n",
        "        data = pd.read_pickle(path)[['content', 'content_morph']]\n",
        "    else:\n",
        "        data = pd.read_pickle(path)[['content', 'content_morph', 'label']]\n",
        "    data = data.dropna()\n",
        "    data.index = pd.RangeIndex(len(data.index))\n",
        "    return data\n",
        "\n",
        "def prepare_train(train_path, mecab=True, filter=False, test_sets=1, test_split=0.3, seed=42, verbose=0):\n",
        "\n",
        "    data = load(train_path, is_predict=False)\n",
        "\n",
        "    if not mecab:\n",
        "        df = data.drop('content_morph', axis=1)\n",
        "    df = data.drop('content', axis=1)\n",
        "    df.columns = ['document', 'label']\n",
        "\n",
        "    if filter:\n",
        "        df['document'] = df['document'].str.replace(\"[^가-힣 ]\",\"\")\n",
        "\n",
        "    splitter = StratifiedShuffleSplit(n_splits=test_sets, test_size=test_split, random_state=seed)\n",
        "    for train_idx, test_idx in splitter.split(df, df['label']):\n",
        "        train_data = df.loc[train_idx]\n",
        "        test_data = df.loc[test_idx]\n",
        "    train_data.index = pd.RangeIndex(len(train_data.index))\n",
        "    test_data.index = pd.RangeIndex(len(test_data.index))\n",
        "    \n",
        "    X_train = train_data['document'].astype(str)\n",
        "    y_train = train_data['label'].astype(int)\n",
        "    X_test = test_data['document'].astype(str)\n",
        "    y_test = test_data['label'].astype(int)\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"train_shape : {X_train.shape}, test_shape: {X_test.shape}\")\n",
        "        print(f\"train set label 비율 \\n {X_train.label.value_counts()/len(X_train)}\")\n",
        "        print(f\"test set label 비율 \\n {X_test.label.value_counts()/len(X_test)}\")\n",
        "\n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "def prepare_pred(pred_path, mecab=True, filter=False, verbose=0):\n",
        "    data = load(pred_path, is_predict=True)\n",
        "\n",
        "    if not mecab:\n",
        "        df = data.drop('content_morph', axis=1)\n",
        "    df = data.drop('content', axis=1)\n",
        "    df.columns = ['document']\n",
        "\n",
        "    if filter:\n",
        "        df['document'] = df['document'].str.replace(\"[^가-힣 ]\",\"\")\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"predict_shape : {df.shape}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def one_hot(label, num_classes):\n",
        "    label = to_categorical(label, num_classes)\n",
        "    print(f\"label shape : {label.shape}\")\n",
        "    return label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqjwzdRZ24hi",
        "colab_type": "text"
      },
      "source": [
        "# [2] 불용어 처리\n",
        "* 사전에 정의한 불용어가 있다면 불용어를 제거합니다.\n",
        "* 이후 단계에서 각 문장을 tokeinize하기 위해 적절한 자료 구조로 구성합니다. 저는 list를 사용했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6fkOnvX23n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stopwords(file_path):\n",
        "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        corpus = f.read()\n",
        "    stopwords = corpus.split('\\n')\n",
        "    return stopwords\n",
        "\n",
        "def get_wordlists(data, filter, **kwargs):\n",
        "    words = []\n",
        "    if filter:\n",
        "        stopwords = get_stopwords(kwargs.get('file_path'))\n",
        "        for idx in range(len(data)):\n",
        "            sent = data[idx].split(' ')\n",
        "            sent = [word for word in sent if not word in stopwords]\n",
        "            words.append(sent)\n",
        "    else:\n",
        "        for idx in data.index:\n",
        "            sent = data[idx].split()\n",
        "            sent = [word for word in sent]\n",
        "            words.append(sent)\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG_o-dMPL3Ii",
        "colab_type": "text"
      },
      "source": [
        "# [3] 토큰화 및 정수 인코딩\n",
        "* 사용할 토크나이저를 미리 import합니다.\n",
        "* 사용할 토크나이저에 따라 아래 함수들은 달라질 수 있습니다. Keras Tokenizer를 염두에 두고 작성한 함수입니다.\n",
        "* 인코딩 시 어휘 집합의 수, 그에 따라 발생하는 빈 데이터를 어떻게 할지 생각하고 진행해야 합니다.\n",
        "* 이후 예측 단계에서 토크나이저가 필요할 수 있기 때문에, `pickle` 객체로 저장해 두었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p076FfXu0mJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_tokenizer(corpus, vocab_size, oov, save_path):\n",
        "    if oov:\n",
        "        oov_token = \"OOV\"\n",
        "        tokenizer = Tokenizer(num_words=vocab_size + 1, oov_token=oov_token)\n",
        "    else:\n",
        "        tokenizer = Tokenizer(num_words=vocab_size + 1)\n",
        "\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    print(f\"Total {len(tokenizer.word_index)} words in tokenizer.\")\n",
        "\n",
        "    now = KST_now()\n",
        "    tok_dir = f\"{save_path}/tokenizer\"\n",
        "    tok_name = f\"{tok_dir}/tok-{now}\"\n",
        "\n",
        "    if not os.path.exists(tok_dir):\n",
        "        os.makedirs(tok_dir)\n",
        "\n",
        "    with open(f\"{tok_dir}/tokenizer_info.txt\", \"a+\", encoding=\"utf-8\") as f:\n",
        "        if oov:\n",
        "            data = f\"\\ndatetime : {now}, tokenizer : {tok_name}, num_words : {vocab_size + 1}, oov : {oov_token}\\n\"\n",
        "        else:\n",
        "            data = f\"\\ndatetime : {now}, tokenizer : {tok_name}, num_words : {vocab_size + 1}, oov : check dropped indices.\\n\"\n",
        "        f.write(data)\n",
        "\n",
        "    with open(f\"{tok_name}.pickle\", 'wb') as tok_f:\n",
        "        pickle.dump(tokenizer, tok_f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    print(f\"Done setting Keras tokenizer! Check {tok_name}.pickle!\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return f\"{tok_name}.pickle\"\n",
        "\n",
        "def tokenize(corpus, tok_name):\n",
        "    with open(tok_name, 'rb') as tok_f:\n",
        "        tokenizer = pickle.load(tok_f)\n",
        "    tokens = tokenizer.texts_to_sequences(corpus)\n",
        "    print(f\"Total {len(tokens)} amounts of tokens.\")\n",
        "    # print(f\"Sample tokens : {tokens[:3]}\")\n",
        "    drop_indices = [idx for idx, sent in enumerate(tokens) if len(sent) < 1]\n",
        "    return tokens, drop_indices\n",
        "\n",
        "# optional : for Keras Tokenizer\n",
        "def check_freq(thre, corpus):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "    total_cnt = len(tokenizer.word_index)\n",
        "    rare_cnt = 0\n",
        "    total_freq = 0\n",
        "    rare_freq = 0\n",
        "    for key, val in tokenizer.word_counts.items():\n",
        "        total_freq += val\n",
        "        if val < thre:\n",
        "            rare_cnt += 1\n",
        "            rare_freq += val\n",
        "\n",
        "    vocab_size = total_cnt - rare_cnt + 1\n",
        "\n",
        "    print(f\"Minimum Threshold : {thre}\")\n",
        "    print(f\"Total Vocabs : {total_cnt}\")\n",
        "    print(f\"Rare Vocabs : {rare_cnt}\")\n",
        "    print(f\"Rare Cnt Proportion : {(rare_cnt/total_cnt)*100}%\")\n",
        "    print(f\"Rare Freq Proportion : {(rare_freq/total_freq)*100}%\")\n",
        "\n",
        "    return total_cnt, rare_cnt, vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRnNI6AU2-FE",
        "colab_type": "text"
      },
      "source": [
        "# [4] 패딩\n",
        "* 문장의 길이를 맞춰주는 작업입니다.\n",
        "* OOV 처리, truncating 및 padding 옵션을 여러 번 바꿔 봤는데, ~~그냥(...)~~ 기본값으로 둘 때 가장 성능이 좋았습니다. 임베딩, 모델 층 구성 등에 더 영향을 받는 것이 아닐까 추측합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPa-wMxkpvdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_sentences(data, save_path, oov):\n",
        "    print(f\"Max Length : {max(len(sent) for sent in data)}\")\n",
        "    print(f\"Average Length : {sum(map(len, data))/len(data)}\")\n",
        "    plt.hist([len(sent) for sent in data], bins=50)\n",
        "    plt.xlabel(\"len of sents\")\n",
        "    plt.ylabel(\"num of sents\")\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    sent_dir = os.path.join(save_path, 'Length_of_Sentences')\n",
        "    sent_pic = f\"{sent_dir}_oov {str(oov)}.png\"\n",
        "    if not os.path.exists(sent_pic):\n",
        "        plt.savefig(sent_pic)\n",
        "    plt.show()\n",
        "\n",
        "def check_len(thre, data):\n",
        "    cnt = 0\n",
        "    for sent in data:\n",
        "        if len(sent) <= thre:\n",
        "            cnt += 1\n",
        "    print(f\"Sentences under {thre} : {(cnt / len(data))*100}%\")\n",
        "\n",
        "def pad_sentences(data, maxlen):\n",
        "    data = pad_sequences(data, maxlen=maxlen)\n",
        "    print(data[:3])\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtjcQpF_pWig",
        "colab_type": "text"
      },
      "source": [
        "# [5] 기본 모델\n",
        "* LSTM, GRU를 활용한 기본 모델을 구성했습니다. 두 모델 모두 파라미터는 동일하게 유지합니다.\n",
        "    - 임베딩 차원을 바꿔봤는데, 100차원일 때 가장 분류 정확도가 높았습니다. 오히려 128, 256 등 차원을 늘리면 늘릴수록 성능이 떨어졌습니다.\n",
        "    - LSTM, GRU 등 여러 층을 쌓고, 활성화 함수를 주는 등 많은 시도를 해봤습니다. 역시 분류 정확도가 낮았습니다. \n",
        "    - NLP 분류의 경우 순환 신경망을 여러 층 구성할수록 오히려 과적합되거나 혹은 단계를 진행할수록 정보가 희석되는(?) 문제가 있는 것 같습니다.\n",
        "* 더 공부해야 합니다. 다만, naive하게 드는 생각으로는 단어 차원에서 임베딩을 진행하고 분류하면, OOV 문제가 있고, 임베딩을 어떻게 하느냐에 따라 모델의 성능이 바뀌는 것 같습니다.\n",
        "* 이후 팀에서 만든 임베딩 모델을 사용하고, attention층을 더하거나 언어 모델 baseline을 구성해 본 후 결과를 비교하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5I-uBtJyHJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_LSTM(input_num, embed_num):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_num, embed_num, mask_zero=True)) # , mask_zero=True\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_GRU(input_num, dim_num):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_num, dim_num, mask_zero=True))\n",
        "    model.add(GRU(128))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMY--LVz5LIs",
        "colab_type": "text"
      },
      "source": [
        "# [6] 모델 기능\n",
        "* 모델을 훈련하고, 가장 좋은 모델을 저장합니다.\n",
        "* 모델의 history를 그림으로 나타냅니다.\n",
        "* 저장된 모델 중 val_loss가 가장 낮은 모델을 가져 옵니다.(혹은 모델 이름을 지정해서 가져올 수도 있습니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCmKG81mQj7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(architecture, name, inputs, labels, epochs=20, val_split=0.25):\n",
        "\n",
        "    model = architecture\n",
        "    \n",
        "    # directory\n",
        "    date = KST_now()[4:14]\n",
        "    model_dir = f'{output_path}/models/{date}'\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    # set checkpoint and early stopping\n",
        "    ck = ModelCheckpoint(filepath = \"{0}/{1}-checkpoint-{{epoch:02d}}-{{val_loss:.4f}}.h5\".format(model_dir, name),\n",
        "                         monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    es = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "    # train\n",
        "    print(model.summary())\n",
        "    history = model.fit(inputs, labels,\n",
        "                        epochs=epochs,\n",
        "                        callbacks=[ck, es],\n",
        "                        validation_split=val_split)\n",
        "    \n",
        "    return history, model_dir\n",
        "\n",
        "def plot_history(hist):\n",
        "    fig, loss_ax = plt.subplots()\n",
        "    \n",
        "    # plot loss\n",
        "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "    loss_ax.set_xlabel('epoch')\n",
        "    loss_ax.set_ylabel('loss')\n",
        "    loss_ax.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # plot accuracy\n",
        "    fig, acc_ax = plt.subplots()\n",
        "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "    acc_ax.set_ylabel('accuracy')\n",
        "    acc_ax.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    return print(\"All Train Done. Check Lowest Val Loss!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNk7e1bT2EWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_model(path, pat):\n",
        "    pattern = pat # saved model format\n",
        "    loss_vals = dict()\n",
        "    for path, subdirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if fnmatch(file, pat):\n",
        "                loss_vals.update({file:int(file[21:25])})\n",
        "    best_model_path = os.path.join(path, min(loss_vals, key=loss_vals.get))\n",
        "    print(best_model_path)\n",
        "    return best_model_path\n",
        "\n",
        "def get_model(path):\n",
        "    model = load_model(path)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZXPfmaN4ry9",
        "colab_type": "text"
      },
      "source": [
        "# [7] 예측\n",
        "* 모델을 가져 옵니다.\n",
        "* 하나의 문장 혹은 예측 데이터에 대해 예측을 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1WyNIlZI89w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_sentence(tagger, tok_name, max_len, input_=True, stop_path=None):\n",
        "\n",
        "    if not input_:\n",
        "        sent = input_\n",
        "    sent = input()\n",
        "    text = tagger.morphs(sent)\n",
        "    \n",
        "    if stop_path is not None:\n",
        "        stopwords = get_stopwords(stop_path)\n",
        "        text = [[word for word in text if not word in stopwords]]\n",
        "    print(text)\n",
        "\n",
        "    print(f\"Using {tok_name}.\")\n",
        "    with open(f'{tok_name}', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "    tokens = tokenizer.texts_to_sequences(text)\n",
        "    padded_text = pad_sentences(tokens, maxlen=max_len)\n",
        "\n",
        "    return padded_text\n",
        "\n",
        "def pred_sentences(sent, model):\n",
        "    prediction = model.predict(sent)\n",
        "    label = np.argmax(prediction)\n",
        "    if label==0:\n",
        "        res=\"unknown\"\n",
        "    elif label==1:\n",
        "        res=\"pos\"\n",
        "    else:\n",
        "        res=\"neg\"\n",
        "    return res\n",
        "\n",
        "def pred_data(model, pred):\n",
        "    pred_raw = model.predict(pred)\n",
        "    print(f\"predict data shape : {pred.shape}\")\n",
        "    preds = np.argmax(pred_raw, axis=1).flatten()\n",
        "    print(f\"length of prediction : {len(preds)}\")\n",
        "    return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TflestP0CVI",
        "colab_type": "text"
      },
      "source": [
        "# [999] etc\n",
        "\n",
        "* 기타 필요한 함수를 정의했습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c53OiN8-rwn",
        "colab_type": "code",
        "outputId": "a6af6032-78c2-4ba7-d282-6cd6f849f3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def KST_now():    \n",
        "    KST = timezone('Asia/Seoul')\n",
        "    now = datetime.datetime.utcnow()\n",
        "    KST_now = utc.localize(now).astimezone(KST)    \n",
        "    return KST_now.strftime(\"KST %Y-%m-%d %H:%M\") \n",
        "\n",
        "KST_now()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KST 2020-04-26 05:04'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG_F0_s4kYW_",
        "colab_type": "text"
      },
      "source": [
        "# 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tLKC0L0pQMM",
        "colab_type": "text"
      },
      "source": [
        "## 첫 번째 작업\n",
        "- OOV 설정하고, 빈 텍스트도 사용했다. \n",
        "- 분류 정확도는 91%였지만, 실제 예측해 보니 ~~(사람이 판단하기에)~~ 다소 이상한 결과가 나온다.\n",
        "    - 노이즈 : OOV 사용, 빈 텍스트 제거하지 않음.\n",
        "    - 인덱스 문제.\n",
        "\n",
        "> *예측 결과 : 좀, 이상하다..*\n",
        "![첫 번째 작업](https://drive.google.com/uc?id=1oUHajjb260qmTY2bsvhfoWiNXRQVPEYi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M45LDP07ptyG",
        "colab_type": "text"
      },
      "source": [
        "## 이후 작업(들)\n",
        "- OOV 사용 안 함, 빈 텍스트 삭제했습니다. mask_zero= True 옵션도 지정해 0으로만 채워진 데이터는 학습 시 가중치 변경에 활용하지 않도록 했습니다.\n",
        "- 기본 LSTM 모델을 사용했을 때 test 정확도가 91% 정도 나옵니다. Baseline 코드에서 파라미터를 조정하여 드라마틱한 성능 향상은 일어나지 않을 것이라 판단해, 이 accuracy를 Baseline 점수로 삼겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCGhp2em7vZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set path\n",
        "my_path = \"/content/drive/My Drive/파이널 프로젝트_개인작업\"\n",
        "project_path = \"/content/drive/My Drive/파이널가쥬앗\"\n",
        "cur_path = f\"{my_path}/SentimentAnalysis\"\n",
        "output_path = f\"{cur_path}/Output\"\n",
        "\n",
        "TRAIN_PATH = f\"{cur_path}/Input/train_input.pickle\"\n",
        "PRED_PATH = f\"{cur_path}/Input/predict_input.pickle\"\n",
        "\n",
        "# set file name\n",
        "stop_name = \"stopwords.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpiGw8PquZ1J",
        "colab_type": "code",
        "outputId": "d87e0453-d6c4-4f1f-8071-3561e96a997d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# load data for train\n",
        "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = prepare_train(TRAIN_PATH, filter=True)\n",
        "print(f\"Sample train input \\n{X_train_raw[:3]} \\nshape : {X_train_raw.shape}\\n\")\n",
        "print(f\"Sample train labels \\n{y_train_raw[:3]} \\nlength : {len(y_train_raw)}\\n\")\n",
        "print(f\"Sample test input \\n{X_test_raw[:3]} \\nshape : {X_test_raw.shape}\\n\")\n",
        "print(f\"Sample test labels \\n{y_test_raw[:3]} \\nlength : {len(y_test_raw)}\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample train input \n",
            "0                    비정규직 분 들 이 숙이 는 거 였었 나요 기억 이 가물가물\n",
            "1    음 제 가 조금 잘못 알 고 있 었 네요 저희 회사 가  개월 기준 으로 운영 되 ...\n",
            "2               프라 푸치노 도 다 셋 팅 해서 갈 기 만 하 면 되 던 거 같 던데\n",
            "Name: document, dtype: object \n",
            "shape : (55748,)\n",
            "\n",
            "Sample train labels \n",
            "0   -1\n",
            "1    1\n",
            "2    0\n",
            "Name: label, dtype: int64 \n",
            "length : 55748\n",
            "\n",
            "Sample test input \n",
            "0                                      저 회사 아직 도 있 군 여\n",
            "1    같이 일 했 던 프랑스 회사 는 진짜 인력 이 계속 돌아가 야 하 는 곳 이 라 그...\n",
            "2                                조선 은 일 하 는 게 매국 인 놈 들\n",
            "Name: document, dtype: object \n",
            "shape : (23893,)\n",
            "\n",
            "Sample test labels \n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "Name: label, dtype: int64 \n",
            "length : 23893\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu_CLT8Tvk6y",
        "colab_type": "code",
        "outputId": "65ac53d5-e96a-409f-f666-608afd95f950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# get morphs\n",
        "stopwords_path = os.path.join(cur_path, stop_name)\n",
        "X_train = get_wordlists(X_train_raw, filter=True, file_path=stopwords_path)\n",
        "X_test = get_wordlists(X_test_raw, filter=True, file_path=stopwords_path)\n",
        "print(f\"train input : {len(X_train)}, test input : {len(X_test)}\")\n",
        "print(f\"Sample train input \\n{X_train[:3]}\\n\")\n",
        "print(f\"Sample test input \\n{X_test[:3]}\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train input : 55748, test input : 23893\n",
            "Sample train input \n",
            "[['비정규직', '분', '숙이', '거', '였었', '나요', '기억', '가물가물'], ['음', '제', '조금', '잘못', '고', '었', '네요', '저희', '회사', '', '개월', '기준', '운영', '고', '어서', '정도', '면', '충분히', '노사', '간', '좋', '합의점', '다', '라고', '생각', '했었', '거든요', '그런데', '니', '시행', '탄력', '근무', '제', '', '개월', '기준', '네요', '이건', '쫌', '문제', '겠', '네요', '일단', '전', '노동자', '시간', '을', '조정', '할', '다는', '가정', '네', '', '시간', '을', '월평균', '사용', '할', '게', '시간', '관리', '좋', '아서', '어느', '정도', '유동', '성', '을', '거', '찬성', '편', '입니다'], ['프라', '푸치노', '다', '셋', '팅', '해서', '갈', '기', '만', '면', '던', '거', '던데']]\n",
            "\n",
            "Sample test input \n",
            "[['저', '회사', '아직', '군', '여'], ['같이', '일', '했', '던', '프랑스', '회사', '진짜', '인력', '계속', '돌아가', '야', '곳', '라', '그런지', '일월', '화수', '목금', '토', '이렇게', '', '일', '근로자', '', '일', '근로자', '돌려서', '일', '년', '내내', '유지', '긴', '더군요', '업종', '이나', '기업', '따라', '다르', '않', '을까', '합니다'], ['조선', '일', '게', '매국', '인', '놈']]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATuvx0GbPcyS",
        "colab_type": "code",
        "outputId": "ea66c695-0a85-4d54-9330-9bfb8c486d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        }
      },
      "source": [
        "for i in range(1, 10):\n",
        "    check_freq(i, X_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum Threshold : 1\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 0\n",
            "Rare Cnt Proportion : 0.0%\n",
            "Rare Freq Proportion : 0.0%\n",
            "Minimum Threshold : 2\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 15355\n",
            "Rare Cnt Proportion : 37.1881811576653%\n",
            "Rare Freq Proportion : 0.9879286761176687%\n",
            "Minimum Threshold : 3\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 21260\n",
            "Rare Cnt Proportion : 51.48946476144345%\n",
            "Rare Freq Proportion : 1.747774828182121%\n",
            "Minimum Threshold : 4\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 24509\n",
            "Rare Cnt Proportion : 59.35819811092274%\n",
            "Rare Freq Proportion : 2.3748891756988204%\n",
            "Minimum Threshold : 5\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 26731\n",
            "Rare Cnt Proportion : 64.73964640348753%\n",
            "Rare Freq Proportion : 2.9467361358638375%\n",
            "Minimum Threshold : 6\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 28262\n",
            "Rare Cnt Proportion : 68.44756599660936%\n",
            "Rare Freq Proportion : 3.439252841541516%\n",
            "Minimum Threshold : 7\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 29469\n",
            "Rare Cnt Proportion : 71.37079195931219%\n",
            "Rare Freq Proportion : 3.905197450622868%\n",
            "Minimum Threshold : 8\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 30395\n",
            "Rare Cnt Proportion : 73.61346573020103%\n",
            "Rare Freq Proportion : 4.322244254829624%\n",
            "Minimum Threshold : 9\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 31195\n",
            "Rare Cnt Proportion : 75.55098086703802%\n",
            "Rare Freq Proportion : 4.734015243247278%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1_n-8cwPKA",
        "colab_type": "code",
        "outputId": "f436c506-2376-4dfa-b84f-6ac9ddb62178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "# set_tokenizer\n",
        "_, _, vocab_size = check_freq(2, X_train)\n",
        "tokenizer = set_tokenizer(X_train, vocab_size, oov=False, save_path=cur_path)\n",
        "print(f\"{tokenizer} : Using only {vocab_size} vocabs in tokenizer\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum Threshold : 2\n",
            "Total Vocabs : 41290\n",
            "Rare Vocabs : 15355\n",
            "Rare Cnt Proportion : 37.1881811576653%\n",
            "Rare Freq Proportion : 0.9879286761176687%\n",
            "Total 41290 words in tokenizer.\n",
            "Done setting Keras tokenizer! Check /content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/tokenizer/tok-KST 2020-04-26 05:04.pickle!\n",
            "\n",
            "\n",
            "/content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/tokenizer/tok-KST 2020-04-26 05:04.pickle : Using only 25936 vocabs in tokenizer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf4LpjfRwfcs",
        "colab_type": "code",
        "outputId": "0a54ee36-661e-4262-875c-c97ffbac3cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "# tokenize data\n",
        "X_train, drop_train = tokenize(X_train, tokenizer)\n",
        "X_test, drop_test = tokenize(X_test, tokenizer)\n",
        "print(f\"train input : {len(X_train)}, test input : {len(X_test)}\\n\")\n",
        "print(f\"Sample train input \\n{X_train[:3]}\\n\")\n",
        "print(f\"Sample test input \\n{X_test[:3]}\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 55748 amounts of tokens.\n",
            "Sample tokens : [[775, 68, 9441, 9, 7316, 149, 1101, 20031], [60, 41, 404, 308, 2, 29, 30, 569, 43, 1, 365, 177, 479, 2, 91, 76, 6, 1162, 1299, 217, 35, 20032, 4, 32, 38, 1034, 629, 343, 33, 202, 699, 34, 41, 1, 365, 177, 30, 361, 4470, 58, 22, 30, 379, 78, 168, 5, 3, 679, 19, 71, 877, 53, 1, 5, 3, 4577, 538, 19, 7, 5, 487, 35, 128, 333, 76, 4258, 95, 3, 9, 925, 588, 45], [20033, 25936, 4, 3528, 3529, 49, 294, 15, 11, 6, 57, 9, 428]]\n",
            "Total 23893 amounts of tokens.\n",
            "Sample tokens : [[55, 43, 226, 830, 161], [241, 8, 20, 57, 1177, 43, 106, 346, 230, 669, 69, 119, 39, 3317, 19916, 23955, 2589, 1480, 292, 1, 8, 221, 1, 8, 221, 6332, 8, 31, 1784, 515, 124, 377, 650, 83, 37, 429, 505, 28, 687, 46], [799, 8, 7, 2164, 23, 199]]\n",
            "train input : 55748, test input : 23893\n",
            "\n",
            "Sample train input \n",
            "[[775, 68, 9441, 9, 7316, 149, 1101, 20031], [60, 41, 404, 308, 2, 29, 30, 569, 43, 1, 365, 177, 479, 2, 91, 76, 6, 1162, 1299, 217, 35, 20032, 4, 32, 38, 1034, 629, 343, 33, 202, 699, 34, 41, 1, 365, 177, 30, 361, 4470, 58, 22, 30, 379, 78, 168, 5, 3, 679, 19, 71, 877, 53, 1, 5, 3, 4577, 538, 19, 7, 5, 487, 35, 128, 333, 76, 4258, 95, 3, 9, 925, 588, 45], [20033, 25936, 4, 3528, 3529, 49, 294, 15, 11, 6, 57, 9, 428]]\n",
            "\n",
            "Sample test input \n",
            "[[55, 43, 226, 830, 161], [241, 8, 20, 57, 1177, 43, 106, 346, 230, 669, 69, 119, 39, 3317, 19916, 23955, 2589, 1480, 292, 1, 8, 221, 1, 8, 221, 6332, 8, 31, 1784, 515, 124, 377, 650, 83, 37, 429, 505, 28, 687, 46], [799, 8, 7, 2164, 23, 199]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BubdGVSw0UK",
        "colab_type": "code",
        "outputId": "066a88b4-2e5f-40e0-c854-1111bd8f691a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "# check empty data\n",
        "print(f\"Should drop {len(drop_train)} train texts. 10 Samples : {drop_train[:10]}\")\n",
        "print(X_train[1330], X_train[1331], X_train[1332])\n",
        "print(f\"Should drop {len(drop_test)} test texts. 10 Samples : {drop_test[:10]}\")\n",
        "print(X_test[113], X_test[114], X_test[115])\n",
        "empty_train = X_train_raw[X_train_raw.index.isin(drop_train)]\n",
        "empty_test = X_test_raw[X_test_raw.index.isin(drop_test)]\n",
        "print(\"\\nCheck Original Empty Texts\\n\")\n",
        "print(f\"Sample empty train input \\n{empty_train[:10]}\\n\")\n",
        "print(f\"Sample empty test input \\n{empty_test[:10]}\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Should drop 88 train texts. 10 Samples : [1331, 1433, 2796, 2854, 4013, 4066, 4196, 4234, 4299, 4875]\n",
            "[3797, 114, 1, 23, 1266, 309, 16, 6540, 653, 1206, 3] [] [2062, 99, 474, 1039]\n",
            "Should drop 48 test texts. 10 Samples : [114, 374, 735, 1079, 1529, 1740, 2242, 2591, 3433, 4110]\n",
            "[4314] [] [1, 25, 666]\n",
            "\n",
            "Check Original Empty Texts\n",
            "\n",
            "Sample empty train input \n",
            "1331               이 보민\n",
            "1433              시사매거진\n",
            "2796                 아항\n",
            "2854               줴인줴인\n",
            "4013                그리고\n",
            "4066                그 때\n",
            "4196               데프 픗\n",
            "4234              팔만대장경\n",
            "4299              안물 안궁\n",
            "4875    빱빠빱빠빠빱빠라밥빠빱빠라밥빠\n",
            "Name: document, dtype: object\n",
            "\n",
            "Sample empty test input \n",
            "114             예이\n",
            "374             장녀\n",
            "735              님\n",
            "1079        섺스자지뷰지\n",
            "1529           왕만두\n",
            "1740            이런\n",
            "2242             와\n",
            "2591          오 홍홍\n",
            "3433           가 자\n",
            "4110    송도동 구타 유발자\n",
            "Name: document, dtype: object\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc98t6JOm7Ty",
        "colab_type": "code",
        "outputId": "17414bf7-536a-4b58-c0ca-fbb3c6ec310c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(\"Now Delete Empty Texts\")\n",
        "X_train = np.delete(X_train, drop_train)\n",
        "y_train = y_train_raw.drop(labels = drop_train)\n",
        "y_train.index = pd.RangeIndex(len(y_train.index))\n",
        "# y_train = np.delete(y_train_raw, drop_train,axis=0)\n",
        "X_test = np.delete(X_test, drop_test)\n",
        "y_test = y_test_raw.drop(labels = drop_test)\n",
        "y_test.index = pd.RangeIndex(len(y_test.index))\n",
        "print(f\"<TRAIN> Input shape : {X_train.shape}, Label length : {len(y_train)}\")\n",
        "print(f\"<TEST> Input shape : {X_test.shape}, Label length : {len(y_test)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now Delete Empty Texts\n",
            "<TRAIN> Input shape : (55660,), Label length : 55660\n",
            "<TEST> Input shape : (23845,), Label length : 23845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ZRVL-4sy0C",
        "colab_type": "code",
        "outputId": "9a5885d2-3286-4514-8ad7-e3d82a89cced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "# check length of sentences\n",
        "for i in range(0, 200, 10):\n",
        "    check_len(i, X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences under 0 : 0.0%\n",
            "Sentences under 10 : 45.591088753144085%\n",
            "Sentences under 20 : 72.20625224577793%\n",
            "Sentences under 30 : 83.05785123966942%\n",
            "Sentences under 40 : 88.43873517786561%\n",
            "Sentences under 50 : 91.49119655048509%\n",
            "Sentences under 60 : 93.44771828961552%\n",
            "Sentences under 70 : 94.75565936040245%\n",
            "Sentences under 80 : 95.59827524254402%\n",
            "Sentences under 90 : 96.27560186848724%\n",
            "Sentences under 100 : 96.78045274883219%\n",
            "Sentences under 110 : 97.14696370822853%\n",
            "Sentences under 120 : 97.46676248652534%\n",
            "Sentences under 130 : 97.72367948257276%\n",
            "Sentences under 140 : 97.90873158462091%\n",
            "Sentences under 150 : 98.06503772906935%\n",
            "Sentences under 160 : 98.21595400646784%\n",
            "Sentences under 170 : 98.3309378368667%\n",
            "Sentences under 180 : 98.43334531081567%\n",
            "Sentences under 190 : 98.5393460294646%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLXz10LIs0AI",
        "colab_type": "code",
        "outputId": "cdfaee07-4ca7-4143-bb79-afcb929f8fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "# pad data\n",
        "max_len = 80\n",
        "X_train = pad_sentences(X_train, max_len)\n",
        "X_test = pad_sentences(X_test, max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "    775    68  9441     9  7316   149  1101 20031]\n",
            " [    0     0     0     0     0     0     0     0    60    41   404   308\n",
            "      2    29    30   569    43     1   365   177   479     2    91    76\n",
            "      6  1162  1299   217    35 20032     4    32    38  1034   629   343\n",
            "     33   202   699    34    41     1   365   177    30   361  4470    58\n",
            "     22    30   379    78   168     5     3   679    19    71   877    53\n",
            "      1     5     3  4577   538    19     7     5   487    35   128   333\n",
            "     76  4258    95     3     9   925   588    45]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0 20033 25936     4  3528  3529\n",
            "     49   294    15    11     6    57     9   428]]\n",
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0    55    43   226   830   161]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0   241     8    20    57  1177    43   106   346\n",
            "    230   669    69   119    39  3317 19916 23955  2589  1480   292     1\n",
            "      8   221     1     8   221  6332     8    31  1784   515   124   377\n",
            "    650    83    37   429   505    28   687    46]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0   799     8     7  2164    23   199]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm6cdOCPs3EL",
        "colab_type": "code",
        "outputId": "3d5fa2d5-55ec-4dbe-d088-a792335799e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# label\n",
        "y_train = one_hot(y_train, 3)\n",
        "y_test = one_hot(y_test, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label shape : (55660, 3)\n",
            "label shape : (23845, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhJD0jX8KQ0R",
        "colab_type": "code",
        "outputId": "5c747130-826b-4d70-89c1-0e5b9a627e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWRqfvpAqMjr",
        "colab_type": "code",
        "outputId": "50305d8f-8aec-404b-d5e1-0e8ea1ad8975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train with basic lstm model\n",
        "lstm = create_LSTM(vocab_size+1, 100)\n",
        "hist, model_dir = train_model(lstm, \"LSTM\", X_train, y_train)\n",
        "plot_history(hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         2593700   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               117248    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 2,711,335\n",
            "Trainable params: 2,711,335\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "1305/1305 [==============================] - ETA: 0s - loss: 0.5198 - accuracy: 0.7971\n",
            "Epoch 00001: val_loss improved from inf to 0.32033, saving model to /content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/Output/models/2020-04-26/LSTM-checkpoint-01-0.3203.h5\n",
            "1305/1305 [==============================] - 188s 144ms/step - loss: 0.5198 - accuracy: 0.7971 - val_loss: 0.3203 - val_accuracy: 0.8924\n",
            "Epoch 2/20\n",
            "1305/1305 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9312\n",
            "Epoch 00002: val_loss improved from 0.32033 to 0.28598, saving model to /content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/Output/models/2020-04-26/LSTM-checkpoint-02-0.2860.h5\n",
            "1305/1305 [==============================] - 187s 143ms/step - loss: 0.2006 - accuracy: 0.9312 - val_loss: 0.2860 - val_accuracy: 0.9067\n",
            "Epoch 3/20\n",
            "1305/1305 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9619\n",
            "Epoch 00003: val_loss did not improve from 0.28598\n",
            "1305/1305 [==============================] - 191s 146ms/step - loss: 0.1148 - accuracy: 0.9619 - val_loss: 0.3174 - val_accuracy: 0.9063\n",
            "Epoch 4/20\n",
            "1305/1305 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9754\n",
            "Epoch 00004: val_loss did not improve from 0.28598\n",
            "1305/1305 [==============================] - 193s 148ms/step - loss: 0.0743 - accuracy: 0.9754 - val_loss: 0.3701 - val_accuracy: 0.9031\n",
            "Epoch 5/20\n",
            "1305/1305 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9829\n",
            "Epoch 00005: val_loss did not improve from 0.28598\n",
            "1305/1305 [==============================] - 191s 146ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.3954 - val_accuracy: 0.8997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "All Train Done. Check Lowest Val Loss!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBT-H28gqUJ5",
        "colab_type": "code",
        "outputId": "f62c53a6-e512-4e17-bbb1-119175775116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# test\n",
        "best_model = get_model(best_model(model_dir, \"*.h5\"))\n",
        "loss_and_metrics = best_model.evaluate(X_test, y_test)\n",
        "print(\"test loss: %.4f\" % (loss_and_metrics[0]))\n",
        "print(\"test accuracy: %.4f\" % (loss_and_metrics[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/Output/models/2020-04-26/LSTM-checkpoint-02-0.2860.h5\n",
            "746/746 [==============================] - 23s 31ms/step - loss: 0.2839 - accuracy: 0.9105\n",
            "test loss: 0.2839\n",
            "test accuracy: 0.9105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OsXZvhWtmGn",
        "colab_type": "code",
        "outputId": "519e0758-9106-4741-f538-2425138f3873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# load data for predict\n",
        "X_pred_raw = prepare_pred(PRED_PATH, filter=True)\n",
        "print(X_pred_raw[:10])\n",
        "\n",
        "# get morphs\n",
        "stopwords_path = os.path.join(cur_path, stop_name)\n",
        "X_pred = get_wordlists(X_train_raw, filter=True, file_path=stopwords_path)\n",
        "print(f\"prediction input : {len(X_pred)}\")\n",
        "print(f\"sample :\")\n",
        "print(X_pred[:10])\n",
        "\n",
        "# tokenize data\n",
        "print(tokenizer)\n",
        "print('')\n",
        "X_pred, drop_pred = tokenize(X_pred, tokenizer)\n",
        "\n",
        "# check empty data\n",
        "print(f\"Should drop {len(drop_pred)} pred texts. 10 Samples : {drop_pred[:10]}\")\n",
        "empty_pred = X_pred_raw[X_pred_raw.index.isin(drop_pred)]\n",
        "print(f\"Sample empty pred input \\n{empty_pred[:10]}\\n\")\n",
        "\n",
        "# delete data\n",
        "print(\"now delete data\")\n",
        "X_pred = np.delete(X_pred, drop_pred, axis=0)\n",
        "print(f\"<PRED> Input shape : {X_pred.shape}\")\n",
        "\n",
        "# pad data\n",
        "X_pred = pad_sentences(X_pred, max_len)\n",
        "\n",
        "# predict with data\n",
        "prediction = pred(best_model, X_pred)\n",
        "print(prediction[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            document\n",
            "0                                            이재명 파이팅\n",
            "1                                   이재명 후보 엄청 지지 합니다\n",
            "2  시간 줄이 면 월급 적 게 줘도 그냥 받 아야지 그런데 대모 할 거 잖 아 개소리 ...\n",
            "3  한 치 도 깔 게 없 는 이재명 을 언론 의 조직 적 왕따 적 행태 에 굴하 지 마...\n",
            "4          자랑 스럽 습니다 끝 까지 지지 합니다 그리고 당신 이  위 로 이 깁니다\n",
            "5       미 췬쉐  본봉 이 적 어 수당 으로 먹 고 사 는 비정규직 서민 들 죽 으라고\n",
            "6  죄명 이 빨갱이 새끼 손가락 혁명군 개 끼 들 저 새끼 는 문죄 인 이 이상 으로 ...\n",
            "7                                       이재명 이 한다면 한다\n",
            "8                                     역시 이재명 밖 엔 없 다\n",
            "9  패널 탄핵 이 기각 되 면 승복 하 시 겠 습니까 재명 저 는 그것 보다 국민 의 ...\n",
            "prediction input : 55748\n",
            "sample :\n",
            "[['비정규직', '분', '숙이', '거', '였었', '나요', '기억', '가물가물'], ['음', '제', '조금', '잘못', '고', '었', '네요', '저희', '회사', '', '개월', '기준', '운영', '고', '어서', '정도', '면', '충분히', '노사', '간', '좋', '합의점', '다', '라고', '생각', '했었', '거든요', '그런데', '니', '시행', '탄력', '근무', '제', '', '개월', '기준', '네요', '이건', '쫌', '문제', '겠', '네요', '일단', '전', '노동자', '시간', '을', '조정', '할', '다는', '가정', '네', '', '시간', '을', '월평균', '사용', '할', '게', '시간', '관리', '좋', '아서', '어느', '정도', '유동', '성', '을', '거', '찬성', '편', '입니다'], ['프라', '푸치노', '다', '셋', '팅', '해서', '갈', '기', '만', '면', '던', '거', '던데'], ['지금', '당장', '자산가', '주머니', '에서', '돈', '겠', '지만'], ['국채', '보상', '공원'], ['확실', '증거', '없', '고', '현장', '어떻게', '돌아가', '는지', '아', '이상', '좋', '게', '좋', '거', '다', '보통', '신고자', '만', '이상', '고', '재수없', '으면', '무고', '성립', '끝', '버리', '니까요'], ['뭔가', '어안', '벙벙', '네요'], ['노가다', '잡부', '', '만', '달', '모아도', '존나', '성실', '거'], ['내용', '잘', '읽', '어', '았', '고', '상황', '처하', '셨', '는지', '개인', '매우', '절박', '심정', '신', '건', '잘', '겠', '습니다', '그런데', '시부', '크', '', '대응', '방식', '으론', '이슈', '대해', '공감', '기', '어려울', '겁니다', '결국', '본인', '지극히', '사', '인', '슈원', '글', '께서', '누구', '언젠가', '겪', '을', '공', '인', '이슈', '라', '시', '지만', '이건', '엄연히', '관점', '차이', '으니', '이상', '언급', '피하', '겠', '음', '끌', '어', '와서', '불', '특정', '다수', '에게', '국민', '청원', '을', '기대', '해', '봐야', '상황', '인데', '루리웹', '유저', '무슨', '계몽', '대상', '인', '마냥', '애', '라도', '도와줘요', '어른', '힘들', '어요', '일단', '시급', '아르바이트', '라도', '해', '셨', '어요', '오죽하면', '루리웹', '고민', '게시판', '글', '을', '올릴까', '생각', '이나', '해', '줬', '으면', '좋', '겠', '네요', '등등', '남', '을', '가르치', '려는', '듯', '말투', '로', '일관', '니', '어', '없', '습니다', '개인', '문제', '공론', '화', '고', '공감대', '얻', '으려면', '그래야', '청원', '클릭', '을', '해', '줄', '거', '아닙니까', '거슬리', '의견', '대해', '적절히', '부드럽', '게', '대처', '모습', '필요', '한데', '에겐', '마저', '결여', '어', '듯', '남', '보다', '못', '다', '인식', '시점', '에서', '이미', '공감', '이나', '설득', '물', '건너', '간', '겁니다'], ['근대', '진짜', '', '소', '관리', '안', '사실', '라', '여태', '까지', '노동법', '그래', '꼬', '아패', '로', '께']]\n",
            "/content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/tokenizer/tok-KST 2020-04-26 01:56.pickle\n",
            "\n",
            "Total 55748 amounts of tokens.\n",
            "Sample tokens : [[775, 68, 9441, 9, 7316, 149, 1101, 20031], [60, 41, 404, 308, 2, 29, 30, 569, 43, 1, 365, 177, 479, 2, 91, 76, 6, 1162, 1299, 217, 35, 20032, 4, 32, 38, 1034, 629, 343, 33, 202, 699, 34, 41, 1, 365, 177, 30, 361, 4470, 58, 22, 30, 379, 78, 168, 5, 3, 679, 19, 71, 877, 53, 1, 5, 3, 4577, 538, 19, 7, 5, 487, 35, 128, 333, 76, 4258, 95, 3, 9, 925, 588, 45], [20033, 25936, 4, 3528, 3529, 49, 294, 15, 11, 6, 57, 9, 428]]\n",
            "Should drop 88 pred texts. 10 Samples : [1331, 1433, 2796, 2854, 4013, 4066, 4196, 4234, 4299, 4875]\n",
            "Sample empty pred input \n",
            "                                               document\n",
            "1331                         생각 하 는 게 딱 초딩 수준 이 라서 아쉽 네\n",
            "1433            무현 이 가 챙겨둔 뒷돈 푼다 이거 지 하하하하 너 도 곧 아웃 이 야\n",
            "2796  대다수  소기업 을 조지 지 않 는 이상 아무 의미 없 지 주간 만 해서  시간 채...\n",
            "2854  제대로 주 면서 고용 하 면 사람 구하 기 어렵 지 않 다 적 게 주 면서 일 많이...\n",
            "4013         단축 이 고 뭐 고 정시 출근 정시 퇴근 만 제발 의무 적 으로 해 주 세요\n",
            "4066  당장 졷소 주  일 칼퇴근 정말 칼 처럼 지킬 수 있 는 법안 이나 만들 어라 그럼...\n",
            "4196  우리 나라 기업 이 썩 어서 그래 개 같이 부려 먹 는 게 우리 나라 현실 이 지 ...\n",
            "4234  그게 무슨 의미 가 잇 냐 노조 가 빵빵 하 거나 공무원 이런 애 들 만 조아 한다...\n",
            "4299  중소기업 님 들 근무 시간 단축 때문 에 기업 부담 이 증가 된다고 그동안 비 정상...\n",
            "4875  우리 는 평균 의 함정 에 속 고 있 습니다 절대 평균 을 믿 지 마십시오 중간값 ...\n",
            "\n",
            "now delete data\n",
            "<PRED> Input shape : (55660,)\n",
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "    775    68  9441     9  7316   149  1101 20031]\n",
            " [    0     0     0     0     0     0     0     0    60    41   404   308\n",
            "      2    29    30   569    43     1   365   177   479     2    91    76\n",
            "      6  1162  1299   217    35 20032     4    32    38  1034   629   343\n",
            "     33   202   699    34    41     1   365   177    30   361  4470    58\n",
            "     22    30   379    78   168     5     3   679    19    71   877    53\n",
            "      1     5     3  4577   538    19     7     5   487    35   128   333\n",
            "     76  4258    95     3     9   925   588    45]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0 20033 25936     4  3528  3529\n",
            "     49   294    15    11     6    57     9   428]]\n",
            "predict data shape : (55660, 80)\n",
            "length of prediction : 55660\n",
            "[0 1 0 0 0 1 0 2 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RxCDQCMZT3D",
        "colab_type": "code",
        "outputId": "3cba6483-8e92-4117-9b1f-deb25347b3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "mecab = Mecab()\n",
        "\n",
        "tok_path = '/content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/tokenizer/tok-KST 2020-04-26 01:55.pickle'\n",
        "\n",
        "sent = convert_sentence(mecab, tok_path, 80, stop_path=stopwords_path)\n",
        "pred_sentences(sent, best_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "배부른 소리 하고 앉아있네. 주52시간 힘들어.\n",
            "[['배부른', '소리', '고', '앉', '아', '네', '.', '52', '시간', '힘들', '어', '.']]\n",
            "Using /content/drive/My Drive/파이널 프로젝트_개인작업/SentimentAnalysis/tokenizer/tok-KST 2020-04-26 01:55.pickle.\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0 6879  180    2 1200   26   53    5  191   18]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}